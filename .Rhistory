# Quanteda package
# This is one of the most extensive packages for dealing with text data in R.
install.packages("quanteda", "quanteda.textplots", "quanteda.textstats")
install.packages("Rtools")
install.packages("RTools")
# Quanteda package
# This is one of the most extensive packages for dealing with text data in R.
library(quanteda)
# Quanteda package
# This is one of the most extensive packages for dealing with text data in R.
install.packages("quanteda")
# Quanteda package
# This is one of the most extensive packages for dealing with text data in R.
install.packages("quanteda.textplots")
# Quanteda package
# This is one of the most extensive packages for dealing with text data in R.
install.packages("quanteda.textstats")
# Quanteda package
# This is one of the most extensive packages for dealing with text data in R.
# install.packages("quanteda") # Remember to install the package in case you haven't used it before
library(quanteda)
library(quanteda.textplots)
library(quanteda.textstats)
library(tidyverse)
# Data - State of the Union speeches of US presidents.
# Each row is a paragraph
url <- 'https://bit.ly/2QoqUQS'
d <- read_csv(url)
head(d) # Let's see the first 6 rows of the data
# Now, we will create a corpus. How does the function works?
?corpus
corp <- corpus(d, text_field = 'text')
corp
install.package("readtext")
install.packages("readtext")
library(readtext)
# How do we deal with other types of data? For example, txt?
url <- "https://github.com/ccs-amsterdam/r-course-material/blob/master/data/files.zip?raw=true"
texts <- readtext(url)
texts
View(texts)
# Again, we can easily transform the text into a corpus
corp2 <- corpus(texts)
corp2
# Let's work with a simple example first
# An example data set
text <-  c(d1 = "Cats are awesome!",
d2 = "We need more cats!",
d3 = "This is a soliloquy about a cat.")
text2 <- tokens(text)
text2
# Create the DTM matrix
dtm <- dfm(text2)
dtm
text2 <- text %>%
tokens(remove_punct = T, remove_numbers = T, remove_symbols = T) %>%   ## tokenize, removing unnecessary noise
tokens_tolower %>%                                                     ## normalize
tokens_remove(stopwords('en')) %>%                                     ## remove stopwords (English)
tokens_wordstem                                                        ## stemming
text2
dtm <- dfm(text2)
dtm
# Wait, was that about stopwords?
stopwords('en')
stopwords('sp')
?stopwords
stopwords('spanish')
# Now, let's pass the corpus of the speeches that we created before through the dfm() function
dtm <- corp %>%
tokens(remove_punct = T, remove_numbers = T, remove_symbols = T) %>%
tokens_tolower %>%
tokens_remove(stopwords('en')) %>%
tokens_wordstem %>%
dfm
dtm
dtm <- dfm_trim(dtm, min_termfreq = 10)
dtm
?dfm_trim()
textplot_wordcloud(dtm, max_words = 50)     ## top 50 (most frequent) words
textplot_wordcloud(dtm, max_words = 50, color = c('blue','red')) ## change colors
textstat_frequency(dtm, n = 10)             ## view the frequencies
# Can we subset the data?
# We can use docvars(dtm) to get a data frame and work as we have done before
is_obama <- docvars(dtm)$President == "Barack Obama"
is_obama
obama_dtm <- dtm[is_obama,]
textplot_wordcloud(obama_dtm, max_words = 25)
is_obama <- docvars(dtm)$President == 'Barack Obama'
ts <- textstat_keyness(dtm, is_obama)
head(ts, 20)    ## view first 20 results
textplot_keyness(ts)
k <- kwic(tokens(corp), 'freedom', window = 7)
head(k, 10)    ## only view first 10 results
terror <- kwic(tokens(corp), 'terror*')
terror_corp <- corpus(terror)
terror_dtm <- terror_corp %>%
tokens(remove_punct = T, remove_numbers = T, remove_symbols = T) %>%
tokens_tolower %>%
tokens_remove(stopwords('en')) %>%
tokens_wordstem %>%
dfm
# Thus, we can focus our analysis on the way that the president talks about terror.
textplot_wordcloud(terror_dtm, max_words = 50)
# A convenient way of using dictionaries is to make a dtm with the columns
# representing dictionary terms.
dict <- dictionary(list(terrorism = 'terror*',
economy = c('econom*', 'tax*', 'job*'),
military = c('army','navy','military','airforce','soldier'),
freedom = c('freedom','liberty')))
dict_dtm <- dfm_lookup(dtm, dict, exclusive=TRUE)
dict_dtm
# You can now perform the analysis with dictionaries
textplot_wordcloud(dict_dtm)
tk <- textstat_keyness(dict_dtm, docvars(dict_dtm)$President == 'Barack Obama')
textplot_keyness(tk)
df <- convert(dict_dtm, to="data.frame")
head(df)
# Creating good dictionaries
kwic(corp, dict$terrorism)
install.packages("usethis")
library(usethis)
edit_git_config()
use_git()
create_github_token()
gitcreds::gitcreds_get()
gitcreds_get()
library(gitcreds)
gitcreds::gitcreds_get()
use_github()
gitcreds_get()
gitcreds::gitcreds_get()
library(gitcreds)
gitcreds_get()
gitcreds_approve()
?gitcreds_get
gitcreds_set(url = "https://github.com")
gitcreds_get()
use_git()
use_github()
